{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_17520\\2055117925.py:6: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# limits the GPU so that it does not crash\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,  Activation, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_paths(dir):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    folds = os.listdir(dir)\n",
    "    for fold in folds:\n",
    "        foldpath = os.path.join(dir, fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "    return filepaths, labels\n",
    "\n",
    "def define_df(files, classes):\n",
    "    Fseries = pd.Series(files, name='filepaths')\n",
    "    Lseries = pd.Series(classes, name='labels')\n",
    "    return pd.concat([Fseries, Lseries], axis=1)\n",
    "\n",
    "def create_df(train_dir, valid_dir, test_dir):\n",
    "    # train dataframe\n",
    "    files, classes = define_paths(train_dir)\n",
    "    train_df = define_df(files, classes)\n",
    "    # validation dataframe\n",
    "    files, classes = define_paths(valid_dir)\n",
    "    valid_df = define_df(files, classes)\n",
    "    # test dataframe\n",
    "    files, classes = define_paths(test_dir)\n",
    "    test_df = define_df(files, classes)\n",
    "    return train_df, valid_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar(img):\n",
    "    return img\n",
    "\n",
    "def create_gens(train_df, valid_df, test_df):\n",
    "    img_size = (224, 224)\n",
    "    tr_gen = ImageDataGenerator(preprocessing_function=scalar, horizontal_flip=True)\n",
    "    ts_gen = ImageDataGenerator(preprocessing_function=scalar)\n",
    "    train_gen = tr_gen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical', color_mode='rgb', shuffle=True)\n",
    "    valid_gen = ts_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical', color_mode='rgb', shuffle=True)\n",
    "    test_gen = ts_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical', color_mode='rgb', shuffle=False)\n",
    "    return train_gen, valid_gen, test_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 613 validated image filenames belonging to 4 classes.\n",
      "Found 72 validated image filenames belonging to 4 classes.\n",
      "Found 315 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = './dataset/train'\n",
    "test_dir = './dataset/test'\n",
    "valid_dir = './dataset/valid'\n",
    "train_df, valid_df, test_df = create_df(train_dir, valid_dir, test_dir)\n",
    "\n",
    "train_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/train\\adenocarcinoma_left.lower.lobe...</td>\n",
       "      <td>adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/train\\adenocarcinoma_left.lower.lobe...</td>\n",
       "      <td>adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/train\\adenocarcinoma_left.lower.lobe...</td>\n",
       "      <td>adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/train\\adenocarcinoma_left.lower.lobe...</td>\n",
       "      <td>adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/train\\adenocarcinoma_left.lower.lobe...</td>\n",
       "      <td>adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>./dataset/train\\squamous.cell.carcinoma_left.h...</td>\n",
       "      <td>squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>./dataset/train\\squamous.cell.carcinoma_left.h...</td>\n",
       "      <td>squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>./dataset/train\\squamous.cell.carcinoma_left.h...</td>\n",
       "      <td>squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>./dataset/train\\squamous.cell.carcinoma_left.h...</td>\n",
       "      <td>squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>./dataset/train\\squamous.cell.carcinoma_left.h...</td>\n",
       "      <td>squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filepaths  \\\n",
       "0    ./dataset/train\\adenocarcinoma_left.lower.lobe...   \n",
       "1    ./dataset/train\\adenocarcinoma_left.lower.lobe...   \n",
       "2    ./dataset/train\\adenocarcinoma_left.lower.lobe...   \n",
       "3    ./dataset/train\\adenocarcinoma_left.lower.lobe...   \n",
       "4    ./dataset/train\\adenocarcinoma_left.lower.lobe...   \n",
       "..                                                 ...   \n",
       "608  ./dataset/train\\squamous.cell.carcinoma_left.h...   \n",
       "609  ./dataset/train\\squamous.cell.carcinoma_left.h...   \n",
       "610  ./dataset/train\\squamous.cell.carcinoma_left.h...   \n",
       "611  ./dataset/train\\squamous.cell.carcinoma_left.h...   \n",
       "612  ./dataset/train\\squamous.cell.carcinoma_left.h...   \n",
       "\n",
       "                                               labels  \n",
       "0          adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib  \n",
       "1          adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib  \n",
       "2          adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib  \n",
       "3          adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib  \n",
       "4          adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib  \n",
       "..                                                ...  \n",
       "608  squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa  \n",
       "609  squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa  \n",
       "610  squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa  \n",
       "611  squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa  \n",
       "612  squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa  \n",
       "\n",
       "[613 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.1827 - accuracy: 0.5889\n",
      "Epoch 1: val_accuracy improved from -inf to 0.47222, saving model to ./model\\best_model.h5\n",
      "20/20 [==============================] - 30s 600ms/step - loss: 1.1827 - accuracy: 0.5889 - val_loss: 2.5605 - val_accuracy: 0.4722\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6403 - accuracy: 0.7830\n",
      "Epoch 2: val_accuracy improved from 0.47222 to 0.66667, saving model to ./model\\best_model.h5\n",
      "20/20 [==============================] - 5s 224ms/step - loss: 0.6403 - accuracy: 0.7830 - val_loss: 0.8766 - val_accuracy: 0.6667\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.8581\n",
      "Epoch 3: val_accuracy did not improve from 0.66667\n",
      "20/20 [==============================] - 4s 188ms/step - loss: 0.3768 - accuracy: 0.8581 - val_loss: 1.1105 - val_accuracy: 0.6389\n",
      "Epoch 4/50\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.3516 - accuracy: 0.8717\n",
      "Epoch 4: val_accuracy did not improve from 0.66667\n",
      "20/20 [==============================] - 4s 174ms/step - loss: 0.3491 - accuracy: 0.8728 - val_loss: 0.7316 - val_accuracy: 0.6528\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3004 - accuracy: 0.9005\n",
      "Epoch 5: val_accuracy did not improve from 0.66667\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.3004 - accuracy: 0.9005 - val_loss: 0.7508 - val_accuracy: 0.6528\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.9250\n",
      "Epoch 6: val_accuracy improved from 0.66667 to 0.72222, saving model to ./model\\best_model.h5\n",
      "20/20 [==============================] - 4s 212ms/step - loss: 0.1994 - accuracy: 0.9250 - val_loss: 0.6051 - val_accuracy: 0.7222\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.9184\n",
      "Epoch 7: val_accuracy did not improve from 0.72222\n",
      "20/20 [==============================] - 5s 252ms/step - loss: 0.2072 - accuracy: 0.9184 - val_loss: 0.5978 - val_accuracy: 0.7222\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.9364\n",
      "Epoch 8: val_accuracy improved from 0.72222 to 0.76389, saving model to ./model\\best_model.h5\n",
      "20/20 [==============================] - 5s 243ms/step - loss: 0.1977 - accuracy: 0.9364 - val_loss: 0.7760 - val_accuracy: 0.7639\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.9347\n",
      "Epoch 9: val_accuracy improved from 0.76389 to 0.77778, saving model to ./model\\best_model.h5\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.1846 - accuracy: 0.9347 - val_loss: 0.5595 - val_accuracy: 0.7778\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9396\n",
      "Epoch 10: val_accuracy improved from 0.77778 to 0.80556, saving model to ./model\\best_model.h5\n",
      "20/20 [==============================] - 6s 294ms/step - loss: 0.1482 - accuracy: 0.9396 - val_loss: 0.6412 - val_accuracy: 0.8056\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.9429\n",
      "Epoch 11: val_accuracy did not improve from 0.80556\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 0.1613 - accuracy: 0.9429 - val_loss: 0.7080 - val_accuracy: 0.7778\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1360 - accuracy: 0.9494\n",
      "Epoch 12: val_accuracy improved from 0.80556 to 0.83333, saving model to ./model\\best_model.h5\n",
      "20/20 [==============================] - 5s 223ms/step - loss: 0.1360 - accuracy: 0.9494 - val_loss: 0.4744 - val_accuracy: 0.8333\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.9560\n",
      "Epoch 13: val_accuracy improved from 0.83333 to 0.87500, saving model to ./model\\best_model.h5\n",
      "20/20 [==============================] - 5s 220ms/step - loss: 0.1336 - accuracy: 0.9560 - val_loss: 0.5339 - val_accuracy: 0.8750\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9413\n",
      "Epoch 14: val_accuracy did not improve from 0.87500\n",
      "20/20 [==============================] - 5s 257ms/step - loss: 0.1517 - accuracy: 0.9413 - val_loss: 0.7483 - val_accuracy: 0.8056\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9592\n",
      "Epoch 15: val_accuracy did not improve from 0.87500\n",
      "20/20 [==============================] - 5s 236ms/step - loss: 0.1244 - accuracy: 0.9592 - val_loss: 0.5383 - val_accuracy: 0.8194\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.9233\n",
      "Epoch 16: val_accuracy did not improve from 0.87500\n",
      "20/20 [==============================] - 4s 200ms/step - loss: 0.2249 - accuracy: 0.9233 - val_loss: 0.7405 - val_accuracy: 0.8056\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9657\n",
      "Epoch 17: val_accuracy did not improve from 0.87500\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 0.1070 - accuracy: 0.9657 - val_loss: 0.4462 - val_accuracy: 0.8611\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9674\n",
      "Epoch 18: val_accuracy did not improve from 0.87500\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.1097 - accuracy: 0.9674 - val_loss: 0.6477 - val_accuracy: 0.7639\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9739\n",
      "Epoch 19: val_accuracy did not improve from 0.87500\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.0815 - accuracy: 0.9739 - val_loss: 0.5295 - val_accuracy: 0.8750\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9739\n",
      "Epoch 20: val_accuracy did not improve from 0.87500\n",
      "20/20 [==============================] - 4s 200ms/step - loss: 0.1033 - accuracy: 0.9739 - val_loss: 0.5557 - val_accuracy: 0.8750\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9804\n",
      "Epoch 21: val_accuracy did not improve from 0.87500\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.0598 - accuracy: 0.9804 - val_loss: 0.5511 - val_accuracy: 0.8750\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9674\n",
      "Epoch 22: val_accuracy improved from 0.87500 to 0.88889, saving model to ./model\\best_model.h5\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 0.0837 - accuracy: 0.9674 - val_loss: 0.5321 - val_accuracy: 0.8889\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9739\n",
      "Epoch 23: val_accuracy improved from 0.88889 to 0.90278, saving model to ./model\\best_model.h5\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 0.0583 - accuracy: 0.9739 - val_loss: 0.4479 - val_accuracy: 0.9028\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0809 - accuracy: 0.9755\n",
      "Epoch 24: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.0809 - accuracy: 0.9755 - val_loss: 0.4520 - val_accuracy: 0.8750\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9739\n",
      "Epoch 25: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.0665 - accuracy: 0.9739 - val_loss: 0.4631 - val_accuracy: 0.8472\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9755\n",
      "Epoch 26: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0707 - accuracy: 0.9755 - val_loss: 0.5076 - val_accuracy: 0.8611\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9657\n",
      "Epoch 27: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 266ms/step - loss: 0.0921 - accuracy: 0.9657 - val_loss: 0.5945 - val_accuracy: 0.8194\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9804\n",
      "Epoch 28: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 262ms/step - loss: 0.0592 - accuracy: 0.9804 - val_loss: 0.6145 - val_accuracy: 0.8472\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9625\n",
      "Epoch 29: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 271ms/step - loss: 0.1148 - accuracy: 0.9625 - val_loss: 0.4980 - val_accuracy: 0.8750\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9772\n",
      "Epoch 30: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 251ms/step - loss: 0.0692 - accuracy: 0.9772 - val_loss: 0.6474 - val_accuracy: 0.8056\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9821\n",
      "Epoch 31: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 246ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.5460 - val_accuracy: 0.8750\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9853\n",
      "Epoch 32: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 238ms/step - loss: 0.0496 - accuracy: 0.9853 - val_loss: 0.5703 - val_accuracy: 0.8889\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9804\n",
      "Epoch 33: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 235ms/step - loss: 0.0451 - accuracy: 0.9804 - val_loss: 0.5590 - val_accuracy: 0.8472\n",
      "Epoch 34/50\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.0468 - accuracy: 0.9868\n",
      "Epoch 34: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 241ms/step - loss: 0.0536 - accuracy: 0.9853 - val_loss: 0.6766 - val_accuracy: 0.8472\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9608\n",
      "Epoch 35: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 244ms/step - loss: 0.1439 - accuracy: 0.9608 - val_loss: 0.7233 - val_accuracy: 0.8194\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9429\n",
      "Epoch 36: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 0.1847 - accuracy: 0.9429 - val_loss: 0.7860 - val_accuracy: 0.8333\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9690\n",
      "Epoch 37: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0834 - accuracy: 0.9690 - val_loss: 0.4407 - val_accuracy: 0.8750\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.9560\n",
      "Epoch 38: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 201ms/step - loss: 0.1291 - accuracy: 0.9560 - val_loss: 0.4304 - val_accuracy: 0.9028\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9706\n",
      "Epoch 39: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.0868 - accuracy: 0.9706 - val_loss: 0.6213 - val_accuracy: 0.8333\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9723\n",
      "Epoch 40: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.0791 - accuracy: 0.9723 - val_loss: 0.4941 - val_accuracy: 0.8750\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.9511\n",
      "Epoch 41: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.1206 - accuracy: 0.9511 - val_loss: 0.5484 - val_accuracy: 0.8472\n",
      "Epoch 42/50\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.0771 - accuracy: 0.9688\n",
      "Epoch 42: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0772 - accuracy: 0.9690 - val_loss: 0.6028 - val_accuracy: 0.8472\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9886\n",
      "Epoch 43: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 208ms/step - loss: 0.0455 - accuracy: 0.9886 - val_loss: 0.6420 - val_accuracy: 0.8472\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9788\n",
      "Epoch 44: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0590 - accuracy: 0.9788 - val_loss: 0.6145 - val_accuracy: 0.8333\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9804\n",
      "Epoch 45: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 210ms/step - loss: 0.0739 - accuracy: 0.9804 - val_loss: 0.5222 - val_accuracy: 0.8333\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9706\n",
      "Epoch 46: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 204ms/step - loss: 0.0769 - accuracy: 0.9706 - val_loss: 0.5841 - val_accuracy: 0.8194\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9723\n",
      "Epoch 47: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.0910 - accuracy: 0.9723 - val_loss: 0.5039 - val_accuracy: 0.8750\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9641\n",
      "Epoch 48: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 206ms/step - loss: 0.0854 - accuracy: 0.9641 - val_loss: 0.6718 - val_accuracy: 0.7917\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9739\n",
      "Epoch 49: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 226ms/step - loss: 0.0663 - accuracy: 0.9739 - val_loss: 0.5804 - val_accuracy: 0.8472\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9788\n",
      "Epoch 50: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 210ms/step - loss: 0.0595 - accuracy: 0.9788 - val_loss: 0.4051 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys()))\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights='imagenet', input_shape=img_shape, pooling='max')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath = './model/best_model.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 7s 186ms/step - loss: 0.0051 - accuracy: 0.9984\n",
      "3/3 [==============================] - 1s 123ms/step - loss: 0.4479 - accuracy: 0.9028\n",
      "10/10 [==============================] - 5s 513ms/step - loss: 0.6223 - accuracy: 0.8032\n",
      "Train Loss:  0.005072366446256638\n",
      "Train Accuracy:  0.9983686804771423\n",
      "--------------------\n",
      "Validation Loss:  0.44785594940185547\n",
      "Validation Accuracy:  0.9027777910232544\n",
      "--------------------\n",
      "Test Loss:  0.6223458647727966\n",
      "Test Accuracy:  0.803174614906311\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('./model/best_model.h5')\n",
    "\n",
    "train_score = model.evaluate(train_gen, verbose=1)\n",
    "valid_score = model.evaluate(valid_gen, verbose=1)\n",
    "test_score = model.evaluate(test_gen, verbose=1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])\n",
    "print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0356 - accuracy: 0.6884\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69444, saving model to ./model\\best_model_resnet.h5\n",
      "20/20 [==============================] - 11s 343ms/step - loss: 1.0356 - accuracy: 0.6884 - val_loss: 1.5893 - val_accuracy: 0.6944\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.9119\n",
      "Epoch 2: val_accuracy improved from 0.69444 to 0.84722, saving model to ./model\\best_model_resnet.h5\n",
      "20/20 [==============================] - 4s 207ms/step - loss: 0.2818 - accuracy: 0.9119 - val_loss: 0.7363 - val_accuracy: 0.8472\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9706\n",
      "Epoch 3: val_accuracy did not improve from 0.84722\n",
      "20/20 [==============================] - 4s 180ms/step - loss: 0.0987 - accuracy: 0.9706 - val_loss: 0.7290 - val_accuracy: 0.7917\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9739\n",
      "Epoch 4: val_accuracy did not improve from 0.84722\n",
      "20/20 [==============================] - 4s 186ms/step - loss: 0.0888 - accuracy: 0.9739 - val_loss: 0.6412 - val_accuracy: 0.8194\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9837\n",
      "Epoch 5: val_accuracy did not improve from 0.84722\n",
      "20/20 [==============================] - 4s 185ms/step - loss: 0.0965 - accuracy: 0.9837 - val_loss: 0.6913 - val_accuracy: 0.8472\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9657\n",
      "Epoch 6: val_accuracy did not improve from 0.84722\n",
      "20/20 [==============================] - 4s 185ms/step - loss: 0.1095 - accuracy: 0.9657 - val_loss: 0.8686 - val_accuracy: 0.8194\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9869\n",
      "Epoch 7: val_accuracy improved from 0.84722 to 0.86111, saving model to ./model\\best_model_resnet.h5\n",
      "20/20 [==============================] - 4s 204ms/step - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.7038 - val_accuracy: 0.8611\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.9804\n",
      "Epoch 8: val_accuracy improved from 0.86111 to 0.88889, saving model to ./model\\best_model_resnet.h5\n",
      "20/20 [==============================] - 4s 207ms/step - loss: 0.1059 - accuracy: 0.9804 - val_loss: 0.6737 - val_accuracy: 0.8889\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9788\n",
      "Epoch 9: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.0704 - accuracy: 0.9788 - val_loss: 0.5924 - val_accuracy: 0.8611\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9853\n",
      "Epoch 10: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.0643 - accuracy: 0.9853 - val_loss: 0.5668 - val_accuracy: 0.8472\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9935\n",
      "Epoch 11: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 187ms/step - loss: 0.0311 - accuracy: 0.9935 - val_loss: 0.5607 - val_accuracy: 0.8750\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9984\n",
      "Epoch 12: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.0147 - accuracy: 0.9984 - val_loss: 0.5541 - val_accuracy: 0.8750\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9935\n",
      "Epoch 13: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 185ms/step - loss: 0.0356 - accuracy: 0.9935 - val_loss: 0.6397 - val_accuracy: 0.8611\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9902\n",
      "Epoch 14: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 0.0391 - accuracy: 0.9902 - val_loss: 0.7111 - val_accuracy: 0.8889\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9804\n",
      "Epoch 15: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.0479 - accuracy: 0.9804 - val_loss: 0.8855 - val_accuracy: 0.8333\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9951\n",
      "Epoch 16: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 180ms/step - loss: 0.0363 - accuracy: 0.9951 - val_loss: 0.7257 - val_accuracy: 0.8611\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9837\n",
      "Epoch 17: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.0511 - accuracy: 0.9837 - val_loss: 0.7881 - val_accuracy: 0.8472\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9935\n",
      "Epoch 18: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.0247 - accuracy: 0.9935 - val_loss: 0.7711 - val_accuracy: 0.8750\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9967\n",
      "Epoch 19: val_accuracy did not improve from 0.88889\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 0.0229 - accuracy: 0.9967 - val_loss: 0.6607 - val_accuracy: 0.8611\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9951\n",
      "Epoch 20: val_accuracy improved from 0.88889 to 0.90278, saving model to ./model\\best_model_resnet.h5\n",
      "20/20 [==============================] - 4s 217ms/step - loss: 0.0329 - accuracy: 0.9951 - val_loss: 0.5620 - val_accuracy: 0.9028\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9951\n",
      "Epoch 21: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.0276 - accuracy: 0.9951 - val_loss: 0.5457 - val_accuracy: 0.9028\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9967\n",
      "Epoch 22: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.0307 - accuracy: 0.9967 - val_loss: 0.5837 - val_accuracy: 0.8889\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9984\n",
      "Epoch 23: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 0.5199 - val_accuracy: 0.9028\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9984\n",
      "Epoch 24: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 0.0346 - accuracy: 0.9984 - val_loss: 0.5663 - val_accuracy: 0.8750\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9967\n",
      "Epoch 25: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.0177 - accuracy: 0.9967 - val_loss: 0.5615 - val_accuracy: 0.8889\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9935\n",
      "Epoch 26: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.5191 - val_accuracy: 0.8889\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9967\n",
      "Epoch 27: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.0198 - accuracy: 0.9967 - val_loss: 0.5516 - val_accuracy: 0.8611\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9984\n",
      "Epoch 28: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 215ms/step - loss: 0.0112 - accuracy: 0.9984 - val_loss: 0.5557 - val_accuracy: 0.8333\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9967\n",
      "Epoch 29: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 203ms/step - loss: 0.0429 - accuracy: 0.9967 - val_loss: 0.4819 - val_accuracy: 0.8889\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9984\n",
      "Epoch 30: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.5585 - val_accuracy: 0.8611\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9951\n",
      "Epoch 31: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.0396 - accuracy: 0.9951 - val_loss: 0.5825 - val_accuracy: 0.8611\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9967\n",
      "Epoch 32: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.0063 - accuracy: 0.9967 - val_loss: 0.5859 - val_accuracy: 0.8611\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9984\n",
      "Epoch 33: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 242ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.5988 - val_accuracy: 0.8611\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9837\n",
      "Epoch 34: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 5s 232ms/step - loss: 0.0426 - accuracy: 0.9837 - val_loss: 1.1241 - val_accuracy: 0.8333\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9886\n",
      "Epoch 35: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.7911 - val_accuracy: 0.8472\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9821\n",
      "Epoch 36: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.0701 - accuracy: 0.9821 - val_loss: 0.8897 - val_accuracy: 0.8194\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9886\n",
      "Epoch 37: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.0313 - accuracy: 0.9886 - val_loss: 0.9436 - val_accuracy: 0.8194\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9918\n",
      "Epoch 38: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0516 - accuracy: 0.9918 - val_loss: 0.9810 - val_accuracy: 0.8056\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9918\n",
      "Epoch 39: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.0292 - accuracy: 0.9918 - val_loss: 0.7884 - val_accuracy: 0.8750\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9918\n",
      "Epoch 40: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.0357 - accuracy: 0.9918 - val_loss: 0.8071 - val_accuracy: 0.8611\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9902\n",
      "Epoch 41: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 0.9063 - val_accuracy: 0.8611\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9935\n",
      "Epoch 42: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.0326 - accuracy: 0.9935 - val_loss: 0.8825 - val_accuracy: 0.8889\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9918\n",
      "Epoch 43: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.0465 - accuracy: 0.9918 - val_loss: 0.9904 - val_accuracy: 0.8611\n",
      "Epoch 44/50\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.0162 - accuracy: 0.9934\n",
      "Epoch 44: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 188ms/step - loss: 0.0161 - accuracy: 0.9935 - val_loss: 1.2513 - val_accuracy: 0.7917\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9886\n",
      "Epoch 45: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.0382 - accuracy: 0.9886 - val_loss: 0.8837 - val_accuracy: 0.8611\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9951\n",
      "Epoch 46: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.0292 - accuracy: 0.9951 - val_loss: 0.9050 - val_accuracy: 0.8611\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9918\n",
      "Epoch 47: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 185ms/step - loss: 0.0469 - accuracy: 0.9918 - val_loss: 1.2136 - val_accuracy: 0.8472\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9918\n",
      "Epoch 48: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 185ms/step - loss: 0.0114 - accuracy: 0.9918 - val_loss: 1.3444 - val_accuracy: 0.8750\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9935\n",
      "Epoch 49: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.0251 - accuracy: 0.9935 - val_loss: 1.0883 - val_accuracy: 0.8889\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9967\n",
      "Epoch 50: val_accuracy did not improve from 0.90278\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 1.1619 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys()))\n",
    "\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=img_shape, pooling='max')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath = './model/best_model_resnet.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 154ms/step - loss: 0.0134 - accuracy: 0.9984\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.5621 - accuracy: 0.9028\n",
      "10/10 [==============================] - 3s 250ms/step - loss: 0.8334 - accuracy: 0.7651\n",
      "Train Loss:  0.013379412703216076\n",
      "Train Accuracy:  0.9983686804771423\n",
      "--------------------\n",
      "Validation Loss:  0.5620526671409607\n",
      "Validation Accuracy:  0.9027777910232544\n",
      "--------------------\n",
      "Test Loss:  0.8334358334541321\n",
      "Test Accuracy:  0.7650793790817261\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "model = load_model('./model/best_model_resnet.h5')\n",
    "\n",
    "train_score = model.evaluate(train_gen, verbose=1)\n",
    "valid_score = model.evaluate(valid_gen, verbose=1)\n",
    "test_score = model.evaluate(test_gen, verbose=1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])\n",
    "print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2604 - accuracy: 0.4927\n",
      "Epoch 1: val_accuracy improved from -inf to 0.19444, saving model to ./model\\best_model_inceptionv3.h5\n",
      "20/20 [==============================] - 14s 381ms/step - loss: 2.2604 - accuracy: 0.4927 - val_loss: 14.2644 - val_accuracy: 0.1944\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.3671 - accuracy: 0.6395\n",
      "Epoch 2: val_accuracy did not improve from 0.19444\n",
      "20/20 [==============================] - 4s 175ms/step - loss: 1.3671 - accuracy: 0.6395 - val_loss: 12.2802 - val_accuracy: 0.1944\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.9772 - accuracy: 0.6868\n",
      "Epoch 3: val_accuracy improved from 0.19444 to 0.30556, saving model to ./model\\best_model_inceptionv3.h5\n",
      "20/20 [==============================] - 4s 210ms/step - loss: 0.9772 - accuracy: 0.6868 - val_loss: 8.2078 - val_accuracy: 0.3056\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7264 - accuracy: 0.7471\n",
      "Epoch 4: val_accuracy improved from 0.30556 to 0.45833, saving model to ./model\\best_model_inceptionv3.h5\n",
      "20/20 [==============================] - 4s 217ms/step - loss: 0.7264 - accuracy: 0.7471 - val_loss: 3.8735 - val_accuracy: 0.4583\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6374 - accuracy: 0.7863\n",
      "Epoch 5: val_accuracy improved from 0.45833 to 0.52778, saving model to ./model\\best_model_inceptionv3.h5\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 0.6374 - accuracy: 0.7863 - val_loss: 2.7252 - val_accuracy: 0.5278\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5813 - accuracy: 0.7879\n",
      "Epoch 6: val_accuracy improved from 0.52778 to 0.56944, saving model to ./model\\best_model_inceptionv3.h5\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.5813 - accuracy: 0.7879 - val_loss: 2.1766 - val_accuracy: 0.5694\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.7977\n",
      "Epoch 7: val_accuracy improved from 0.56944 to 0.59722, saving model to ./model\\best_model_inceptionv3.h5\n",
      "20/20 [==============================] - 4s 204ms/step - loss: 0.5659 - accuracy: 0.7977 - val_loss: 1.8063 - val_accuracy: 0.5972\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.8238\n",
      "Epoch 8: val_accuracy did not improve from 0.59722\n",
      "20/20 [==============================] - 4s 174ms/step - loss: 0.5687 - accuracy: 0.8238 - val_loss: 1.3129 - val_accuracy: 0.5833\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.8385\n",
      "Epoch 9: val_accuracy improved from 0.59722 to 0.62500, saving model to ./model\\best_model_inceptionv3.h5\n",
      "20/20 [==============================] - 4s 216ms/step - loss: 0.4585 - accuracy: 0.8385 - val_loss: 1.4155 - val_accuracy: 0.6250\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8679\n",
      "Epoch 10: val_accuracy did not improve from 0.62500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.4609 - accuracy: 0.8679 - val_loss: 1.2799 - val_accuracy: 0.5694\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.8874\n",
      "Epoch 11: val_accuracy improved from 0.62500 to 0.69444, saving model to ./model\\best_model_inceptionv3.h5\n",
      "20/20 [==============================] - 4s 204ms/step - loss: 0.3577 - accuracy: 0.8874 - val_loss: 0.9766 - val_accuracy: 0.6944\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.8923\n",
      "Epoch 12: val_accuracy did not improve from 0.69444\n",
      "20/20 [==============================] - 4s 175ms/step - loss: 0.2909 - accuracy: 0.8923 - val_loss: 0.8596 - val_accuracy: 0.6944\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.9005\n",
      "Epoch 13: val_accuracy did not improve from 0.69444\n",
      "20/20 [==============================] - 4s 178ms/step - loss: 0.2640 - accuracy: 0.9005 - val_loss: 0.8748 - val_accuracy: 0.6944\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2765 - accuracy: 0.9021\n",
      "Epoch 14: val_accuracy did not improve from 0.69444\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.2765 - accuracy: 0.9021 - val_loss: 0.9058 - val_accuracy: 0.6806\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.8760\n",
      "Epoch 15: val_accuracy did not improve from 0.69444\n",
      "20/20 [==============================] - 4s 187ms/step - loss: 0.4501 - accuracy: 0.8760 - val_loss: 0.7937 - val_accuracy: 0.6528\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.8679\n",
      "Epoch 16: val_accuracy did not improve from 0.69444\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.3322 - accuracy: 0.8679 - val_loss: 0.9747 - val_accuracy: 0.6944\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.8777\n",
      "Epoch 17: val_accuracy improved from 0.69444 to 0.73611, saving model to ./model\\best_model_inceptionv3.h5\n",
      "20/20 [==============================] - 4s 200ms/step - loss: 0.3458 - accuracy: 0.8777 - val_loss: 0.9134 - val_accuracy: 0.7361\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2802 - accuracy: 0.8907\n",
      "Epoch 18: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.2802 - accuracy: 0.8907 - val_loss: 0.7936 - val_accuracy: 0.7083\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9364\n",
      "Epoch 19: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 4s 175ms/step - loss: 0.1741 - accuracy: 0.9364 - val_loss: 1.0551 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.9038\n",
      "Epoch 20: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 4s 172ms/step - loss: 0.2786 - accuracy: 0.9038 - val_loss: 0.8703 - val_accuracy: 0.6389\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.8842\n",
      "Epoch 21: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.4079 - accuracy: 0.8842 - val_loss: 0.9162 - val_accuracy: 0.6806\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.9152\n",
      "Epoch 22: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.2864 - accuracy: 0.9152 - val_loss: 0.9080 - val_accuracy: 0.6944\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.9119\n",
      "Epoch 23: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 0.2320 - accuracy: 0.9119 - val_loss: 0.8823 - val_accuracy: 0.7222\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9103\n",
      "Epoch 24: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.2409 - accuracy: 0.9103 - val_loss: 0.8836 - val_accuracy: 0.6944\n",
      "Epoch 25/50\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.2064 - accuracy: 0.9260\n",
      "Epoch 25: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.2055 - accuracy: 0.9266 - val_loss: 0.8620 - val_accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9543\n",
      "Epoch 26: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.1582 - accuracy: 0.9543 - val_loss: 0.7942 - val_accuracy: 0.7083\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2952 - accuracy: 0.9005\n",
      "Epoch 27: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 0.2952 - accuracy: 0.9005 - val_loss: 1.0091 - val_accuracy: 0.6944\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.9201\n",
      "Epoch 28: val_accuracy did not improve from 0.73611\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.2384 - accuracy: 0.9201 - val_loss: 0.8531 - val_accuracy: 0.6667\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.9250\n",
      "Epoch 29: val_accuracy improved from 0.73611 to 0.75000, saving model to ./model\\best_model_inceptionv3.h5\n",
      "20/20 [==============================] - 4s 211ms/step - loss: 0.2520 - accuracy: 0.9250 - val_loss: 0.6889 - val_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1983 - accuracy: 0.9233\n",
      "Epoch 30: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 174ms/step - loss: 0.1983 - accuracy: 0.9233 - val_loss: 0.7965 - val_accuracy: 0.6944\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.9462\n",
      "Epoch 31: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.1931 - accuracy: 0.9462 - val_loss: 0.7760 - val_accuracy: 0.7083\n",
      "Epoch 32/50\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.1304 - accuracy: 0.9589\n",
      "Epoch 32: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 174ms/step - loss: 0.1312 - accuracy: 0.9592 - val_loss: 0.6848 - val_accuracy: 0.7083\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9592\n",
      "Epoch 33: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 0.0970 - accuracy: 0.9592 - val_loss: 1.0161 - val_accuracy: 0.6528\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.9396\n",
      "Epoch 34: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 174ms/step - loss: 0.2501 - accuracy: 0.9396 - val_loss: 0.7443 - val_accuracy: 0.6944\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2651 - accuracy: 0.9184\n",
      "Epoch 35: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 175ms/step - loss: 0.2651 - accuracy: 0.9184 - val_loss: 1.3262 - val_accuracy: 0.6944\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2069 - accuracy: 0.9462\n",
      "Epoch 36: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.2069 - accuracy: 0.9462 - val_loss: 1.1957 - val_accuracy: 0.6667\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.9315\n",
      "Epoch 37: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 186ms/step - loss: 0.1956 - accuracy: 0.9315 - val_loss: 1.2128 - val_accuracy: 0.6806\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.9576\n",
      "Epoch 38: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 3s 178ms/step - loss: 0.1967 - accuracy: 0.9576 - val_loss: 1.1686 - val_accuracy: 0.6667\n",
      "Epoch 39/50\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.1216 - accuracy: 0.9622\n",
      "Epoch 39: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.1254 - accuracy: 0.9608 - val_loss: 1.2127 - val_accuracy: 0.6528\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.9592\n",
      "Epoch 40: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 3s 180ms/step - loss: 0.1564 - accuracy: 0.9592 - val_loss: 1.2041 - val_accuracy: 0.6389\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9706\n",
      "Epoch 41: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 174ms/step - loss: 0.1078 - accuracy: 0.9706 - val_loss: 1.1545 - val_accuracy: 0.6667\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9755\n",
      "Epoch 42: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.0966 - accuracy: 0.9755 - val_loss: 1.0440 - val_accuracy: 0.6944\n",
      "Epoch 43/50\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.0994 - accuracy: 0.9638\n",
      "Epoch 43: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 173ms/step - loss: 0.1065 - accuracy: 0.9608 - val_loss: 0.9274 - val_accuracy: 0.7083\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9625\n",
      "Epoch 44: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 3s 172ms/step - loss: 0.1040 - accuracy: 0.9625 - val_loss: 1.0648 - val_accuracy: 0.7222\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9625\n",
      "Epoch 45: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 176ms/step - loss: 0.1384 - accuracy: 0.9625 - val_loss: 1.0312 - val_accuracy: 0.6944\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9543\n",
      "Epoch 46: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.1197 - accuracy: 0.9543 - val_loss: 1.0893 - val_accuracy: 0.6944\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9723\n",
      "Epoch 47: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 173ms/step - loss: 0.0856 - accuracy: 0.9723 - val_loss: 1.0997 - val_accuracy: 0.6944\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4006 - accuracy: 0.9511\n",
      "Epoch 48: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 172ms/step - loss: 0.4006 - accuracy: 0.9511 - val_loss: 1.0624 - val_accuracy: 0.6806\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.9331\n",
      "Epoch 49: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 0.2230 - accuracy: 0.9331 - val_loss: 1.1945 - val_accuracy: 0.7222\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.9478\n",
      "Epoch 50: val_accuracy did not improve from 0.75000\n",
      "20/20 [==============================] - 4s 175ms/step - loss: 0.2403 - accuracy: 0.9478 - val_loss: 1.0721 - val_accuracy: 0.7361\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys()))\n",
    "\n",
    "base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=img_shape, pooling='max')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath = './model/best_model_inceptionv3.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 5s 153ms/step - loss: 0.0785 - accuracy: 0.9690\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.6890 - accuracy: 0.7500\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 1.9230 - accuracy: 0.4730\n",
      "Train Loss:  0.07848265767097473\n",
      "Train Accuracy:  0.9690048694610596\n",
      "--------------------\n",
      "Validation Loss:  0.6889743804931641\n",
      "Validation Accuracy:  0.75\n",
      "--------------------\n",
      "Test Loss:  1.9230111837387085\n",
      "Test Accuracy:  0.4730158746242523\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "model = load_model('./model/best_model_inceptionv3.h5')\n",
    "\n",
    "train_score = model.evaluate(train_gen, verbose=1)\n",
    "valid_score = model.evaluate(valid_gen, verbose=1)\n",
    "test_score = model.evaluate(test_gen, verbose=1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])\n",
    "print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "input_shape = img_shape\n",
    "\n",
    "model_inceptionv3 = load_model('./model/best_model_inceptionv3.h5')\n",
    "model = load_model('./model/best_model.h5')\n",
    "model_resnet = load_model('./model/best_model_resnet.h5')\n",
    "\n",
    "input_layer = Input(shape=(input_shape))\n",
    "\n",
    "output_inceptionv3 = model_inceptionv3(input_layer)\n",
    "output_model = model(input_layer)\n",
    "output_resnet = model_resnet(input_layer)\n",
    "\n",
    "average = Average()([output_inceptionv3, output_model, output_resnet])\n",
    "\n",
    "ensemble_model = Model(inputs=input_layer, outputs=average)\n",
    "\n",
    "ensemble_model.save('./model/final_ensemble_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_17520\\1939376018.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  preds = model.predict_generator(test_gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 3 0 0 0 0 1 0 0 0 3 0 0 3 0 3 0 3 0 0 0 0 0 0 3 0 0 0 0 0 0 1 3 0 0\n",
      " 1 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 3 0 0\n",
      " 0 3 0 0 0 1 0 0 0 3 0 3 0 0 3 0 0 0 0 1 0 0 0 0 3 0 0 3 0 0 0 3 1 3 1 0 3\n",
      " 0 0 3 0 0 3 0 0 3 1 1 1 1 3 0 0 1 1 3 1 0 3 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 3 1 1 1 3 1 1 1 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 0\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 1 3 3 3 3 0 3 3 3 3 3 0 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./model/final_ensemble_model.h5')\n",
    "preds = model.predict_generator(test_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "10/10 [==============================] - 11s 318ms/step - loss: 0.5464 - accuracy: 0.8286\n",
      "Test Loss: 0.5463975071907043\n",
      "Test Accuracy: 0.8285714387893677\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('./model/final_ensemble_model.h5')\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "test_score = model.evaluate(test_gen, verbose=1)\n",
    "\n",
    "print(\"Test Loss:\", test_score[0])\n",
    "print(\"Test Accuracy:\", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks=np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized Confusion Matrix')\n",
    "    else:\n",
    "        print('Confusion Matrix, Without Normaization')\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicated Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix, Without Normaization\n",
      "[[89  7  0 24]\n",
      " [ 9 37  0  5]\n",
      " [ 1  0 53  0]\n",
      " [ 7  1  0 82]]\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "         adenocarcinoma       0.84      0.74      0.79       120\n",
      "   large-cell-carcinoma       0.82      0.73      0.77        51\n",
      "                 normal       1.00      0.98      0.99        54\n",
      "squamous-cell-carcinoma       0.74      0.91      0.82        90\n",
      "\n",
      "               accuracy                           0.83       315\n",
      "              macro avg       0.85      0.84      0.84       315\n",
      "           weighted avg       0.84      0.83      0.83       315\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_names = ['adenocarcinoma', 'large-cell-carcinoma', 'normal', 'squamous-cell-carcinoma']\n",
    "\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "plot_confusion_matrix(cm=cm, classes=target_names, title='Confusion Matrix')\n",
    "\n",
    "print(classification_report(test_gen.classes, y_pred, target_names=target_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
